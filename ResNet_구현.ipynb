{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet 구현.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOUM2yBpU1+elpGiCmR7mLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nohyunjin/DeepLearning/blob/main/ResNet_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-oB0MMIKIwd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztvZ2HabbPhr",
        "outputId": "a6254428-e273-4495-b175-9d6039012d82"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n",
        "print('train_X shape:', train_X.shape)\n",
        "print(test_X.shape[0], 'test samples')\n",
        "\n",
        "input_shape = train_X.shape[1:]\n",
        "\n",
        "train_X = train_X.astype('float32') / 255\n",
        "test_X = test_X.astype('float32') / 255\n",
        "\n",
        "inputs = Input(shape = input_shape)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')\n",
        "x = conv(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu', kernel_regularizer = l2(1e-4))\n",
        "y = conv(x)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', kernel_regularizer = l2(1e-4))\n",
        "y = conv(y)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "x = keras.layers.add([x, y])\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu', kernel_regularizer = l2(1e-4))\n",
        "y = conv(x)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', kernel_regularizer = l2(1e-4))\n",
        "y = conv(y)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "x = keras.layers.add([x, y])\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu', kernel_regularizer = l2(1e-4))\n",
        "y = conv(x)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', kernel_regularizer = l2(1e-4))\n",
        "y = conv(y)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "x = keras.layers.add([x, y])\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu', kernel_regularizer = l2(1e-4))\n",
        "y = conv(x)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "conv = Conv2D(filters = 32, kernel_size = 3, padding = 'same', kernel_regularizer = l2(1e-4))\n",
        "y = conv(y)\n",
        "y = BatchNormalization()(y)\n",
        "\n",
        "x = keras.layers.add([x, y])\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = AveragePooling2D(pool_size = 8)(x)\n",
        "y = Flatten()(x)\n",
        "\n",
        "y = Dense(512, activation = 'relu')(y)\n",
        "outputs = Dense(NUM_CLASSES, activation = 'softmax')(y)\n",
        "\n",
        "model = Model(inputs = inputs, outputs = outputs)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nETrxMUnKgdI",
        "outputId": "b6a63ec8-48d8-42fc-9949-4b62eb6c7e27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_X shape: (50000, 32, 32, 3)\n",
            "10000 test samples\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 32)   896         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_5[0][0]',  \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 32)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 32)   9248        ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 32, 32, 32)   0           ['activation_2[0][0]',           \n",
            "                                                                  'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 32)   0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 32)   9248        ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 32)  128         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 32)   9248        ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 32, 32)   0           ['activation_3[0][0]',           \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 32)   0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 32)   9248        ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 32, 32, 32)  128         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 32)   9248        ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 32)  128         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 32, 32, 32)   0           ['activation_4[0][0]',           \n",
            "                                                                  'batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 32)   0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 4, 4, 32)    0           ['activation_5[0][0]']           \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 512)          0           ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          262656      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 10)           5130        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 343,818\n",
            "Trainable params: 343,242\n",
            "Non-trainable params: 576\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 200\n",
        "\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_model-{epoch:03d}-{val_accuracy:.4f}.h5'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath = filepath, monitor = 'val_accuracy', save_best_only = True, verbos = 1)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 90:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 60:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 40:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate:', lr)    \n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "early_stopping = EarlyStopping(monitor = 'loss', patience = 5)\n",
        "\n",
        "my_callbacks = [checkpoint, lr_scheduler, early_stopping]\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(train_X, train_y, validation_data = (test_X, test_y), epochs = EPOCHS, batch_size = BATCH_SIZE, callbacks = my_callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ggm2b7Ma0a",
        "outputId": "0ea3c76d-5902-462d-e5c9-44d8b53925e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.001\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 10s 33ms/step - loss: 1.4161 - accuracy: 0.5039 - val_loss: 2.8731 - val_accuracy: 0.1600 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 2/100\n",
            "  1/250 [..............................] - ETA: 7s - loss: 1.1647 - accuracy: 0.5900"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 8s 31ms/step - loss: 0.9753 - accuracy: 0.6630 - val_loss: 1.6456 - val_accuracy: 0.4442 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.8220 - accuracy: 0.7195 - val_loss: 0.9356 - val_accuracy: 0.6826 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.7244 - accuracy: 0.7540 - val_loss: 1.0911 - val_accuracy: 0.6486 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.6583 - accuracy: 0.7785 - val_loss: 0.7134 - val_accuracy: 0.7637 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.5935 - accuracy: 0.8021 - val_loss: 0.6832 - val_accuracy: 0.7713 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.5490 - accuracy: 0.8185 - val_loss: 0.7668 - val_accuracy: 0.7512 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.5046 - accuracy: 0.8339 - val_loss: 0.7101 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.4591 - accuracy: 0.8503 - val_loss: 0.6666 - val_accuracy: 0.7865 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.4302 - accuracy: 0.8597 - val_loss: 0.6830 - val_accuracy: 0.7908 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.3991 - accuracy: 0.8710 - val_loss: 0.7265 - val_accuracy: 0.7673 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.3741 - accuracy: 0.8810 - val_loss: 0.6799 - val_accuracy: 0.7924 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.3400 - accuracy: 0.8933 - val_loss: 0.8025 - val_accuracy: 0.7634 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.3189 - accuracy: 0.9013 - val_loss: 0.9438 - val_accuracy: 0.7469 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.2854 - accuracy: 0.9128 - val_loss: 0.7739 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.2671 - accuracy: 0.9194 - val_loss: 0.8084 - val_accuracy: 0.7860 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.2498 - accuracy: 0.9261 - val_loss: 0.8000 - val_accuracy: 0.7785 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.2271 - accuracy: 0.9337 - val_loss: 0.8229 - val_accuracy: 0.7827 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.2036 - accuracy: 0.9417 - val_loss: 0.9391 - val_accuracy: 0.7637 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1849 - accuracy: 0.9493 - val_loss: 0.9123 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1745 - accuracy: 0.9519 - val_loss: 1.0790 - val_accuracy: 0.7568 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.1616 - accuracy: 0.9575 - val_loss: 0.8833 - val_accuracy: 0.7952 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.1509 - accuracy: 0.9613 - val_loss: 0.7992 - val_accuracy: 0.8082 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1397 - accuracy: 0.9659 - val_loss: 1.0028 - val_accuracy: 0.7754 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1377 - accuracy: 0.9667 - val_loss: 0.9851 - val_accuracy: 0.7884 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1303 - accuracy: 0.9687 - val_loss: 1.0820 - val_accuracy: 0.7775 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1302 - accuracy: 0.9696 - val_loss: 1.0099 - val_accuracy: 0.7892 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1133 - accuracy: 0.9759 - val_loss: 1.0209 - val_accuracy: 0.7916 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1141 - accuracy: 0.9750 - val_loss: 1.1455 - val_accuracy: 0.7674 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1108 - accuracy: 0.9762 - val_loss: 1.0687 - val_accuracy: 0.7934 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1064 - accuracy: 0.9781 - val_loss: 1.0425 - val_accuracy: 0.7902 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1126 - accuracy: 0.9756 - val_loss: 1.1007 - val_accuracy: 0.7896 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1115 - accuracy: 0.9766 - val_loss: 1.1647 - val_accuracy: 0.7920 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1114 - accuracy: 0.9766 - val_loss: 1.1030 - val_accuracy: 0.8052 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1002 - accuracy: 0.9806 - val_loss: 1.1630 - val_accuracy: 0.7789 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0922 - accuracy: 0.9839 - val_loss: 1.2217 - val_accuracy: 0.7849 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0925 - accuracy: 0.9832 - val_loss: 1.2096 - val_accuracy: 0.7860 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1049 - accuracy: 0.9788 - val_loss: 1.3267 - val_accuracy: 0.7679 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.1037 - accuracy: 0.9795 - val_loss: 1.1913 - val_accuracy: 0.7966 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0877 - accuracy: 0.9856 - val_loss: 1.1641 - val_accuracy: 0.7854 - lr: 0.0010\n",
            "Learning rate: 0.001\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0925 - accuracy: 0.9831 - val_loss: 1.1636 - val_accuracy: 0.8002 - lr: 0.0010\n",
            "Learning rate: 0.0001\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0601 - accuracy: 0.9964 - val_loss: 1.0300 - val_accuracy: 0.8192 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0503 - accuracy: 0.9996 - val_loss: 1.0289 - val_accuracy: 0.8229 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 1.0347 - val_accuracy: 0.8245 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 1.0403 - val_accuracy: 0.8262 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.8253 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.0493 - val_accuracy: 0.8283 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 1.0547 - val_accuracy: 0.8280 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.0599 - val_accuracy: 0.8283 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 1.0679 - val_accuracy: 0.8278 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 1.0695 - val_accuracy: 0.8299 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 1.0740 - val_accuracy: 0.8292 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.8296 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 1.0843 - val_accuracy: 0.8296 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 1.0844 - val_accuracy: 0.8300 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 1.0895 - val_accuracy: 0.8309 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 1.0936 - val_accuracy: 0.8295 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.8295 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.8308 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 1.1024 - val_accuracy: 0.8301 - lr: 1.0000e-04\n",
            "Learning rate: 0.0001\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.8311 - lr: 1.0000e-04\n",
            "Learning rate: 1e-05\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.8313 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.8315 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 1.1275 - val_accuracy: 0.8316 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 1.1284 - val_accuracy: 0.8309 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.1274 - val_accuracy: 0.8302 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.8310 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.1296 - val_accuracy: 0.8307 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 1.1305 - val_accuracy: 0.8308 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 1.1306 - val_accuracy: 0.8309 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.1327 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 1.1345 - val_accuracy: 0.8314 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.1361 - val_accuracy: 0.8307 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.1370 - val_accuracy: 0.8309 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.1374 - val_accuracy: 0.8303 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.1401 - val_accuracy: 0.8316 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.8299 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.8301 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.1454 - val_accuracy: 0.8299 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.1434 - val_accuracy: 0.8305 - lr: 1.0000e-05\n",
            "Learning rate: 1e-05\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.1438 - val_accuracy: 0.8307 - lr: 1.0000e-05\n",
            "Learning rate: 1e-06\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.1524 - val_accuracy: 0.8298 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.1538 - val_accuracy: 0.8294 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.1534 - val_accuracy: 0.8301 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.1537 - val_accuracy: 0.8297 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.1541 - val_accuracy: 0.8294 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.1540 - val_accuracy: 0.8294 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.8292 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.1550 - val_accuracy: 0.8295 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.1547 - val_accuracy: 0.8296 - lr: 1.0000e-06\n",
            "Learning rate: 1e-06\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.1558 - val_accuracy: 0.8297 - lr: 1.0000e-06\n",
            "Learning rate: 5e-07\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.1566 - val_accuracy: 0.8295 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.1573 - val_accuracy: 0.8302 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.8295 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.1579 - val_accuracy: 0.8298 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.1573 - val_accuracy: 0.8297 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.1579 - val_accuracy: 0.8298 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.1586 - val_accuracy: 0.8301 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.1584 - val_accuracy: 0.8299 - lr: 5.0000e-07\n",
            "Learning rate: 5e-07\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 8s 31ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.1579 - val_accuracy: 0.8299 - lr: 5.0000e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_X, test_y, verbose = 1)\n",
        "print('Test loss', scores[0])\n",
        "print('Test accuracy', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWb66k5nN0hr",
        "outputId": "d2572571-72fa-4327-af2f-cc5616a0f602"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 1.1579 - accuracy: 0.8300\n",
            "Test loss 1.1579314470291138\n",
            "Test accuracy 0.8299999833106995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(history.history.keys())\n",
        "# Accuracy 시각화\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('modle_accuracy')\n",
        "plt.ylabel('accuracc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.show()\n",
        "# Loss 시각화\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "AlFvbZhYUssX",
        "outputId": "382e645b-a00c-45f4-cee7-abaca79a5cd4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9bbVanmFVRiT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}